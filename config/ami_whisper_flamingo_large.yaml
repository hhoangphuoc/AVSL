train_name: whisper_flamingo_ft_ami

# Data paths for Hugging Face datasets (must be loadable by load_from_disk)
# NOTE: This is the path to the validated videos - FIXME: uncomment later after the clean dataset is splitted
train_data_path: "/home/s2587130/AVSL/data/ami/ami_clean/train"  
val_data_path: "/home/s2587130/AVSL/data/ami/ami_clean/val"
test_data_path: "/home/s2587130/AVSL/data/ami/ami_clean/test"

# AGGRESSIVE MEMORY OPTIMIZATION ===============================================
# Max audio length for LengthBatchSampler (in samples, e.g., 5s * 16000 = 80000)
audio_max_length: 80000 # Reduced from 160000 (10s) to 80000 (5s) for memory saving

# Max audio length for whisper.pad_or_trim (in samples)
dataset_audio_max_length: 80000  # Reduced from 160000 (10s) to 5s

# Max duration in seconds to filter dataset samples before training/evaluation
max_duration_filter_seconds: 5.0  # Reduced from 10.0 to match dataset_audio_max_length

# Batch sizes - set to absolute minimum
batch_size: 1 
eval_batch_size: 1 
gradient_accumulation_steps: 32  # Increased from 16 to maintain effective batch size

# Memory-specific settings
num_worker: 0 # Disable multiprocessing to save memory
pin_memory: false # Disable pinned memory
persistent_workers: false # Disable persistent workers
validate_every_n_batches: 2000  # Increased from 1000 to reduce validation frequency
num_sanity_val_steps: 0 # Disable sanity validation to save memory

# Precision and checkpointing
precision: bf16 # Use bfloat16 instead of 16 for better memory efficiency
enable_gradient_checkpointing: true
reload_dataloaders_every_n_epochs: 0 # Disable reloading to save memory
sync_batchnorm: false # Disable sync batch norm for single GPU

# Model settings for memory optimization
freeze_video_model: True # Keep video model frozen to save memory
freeze_video_batch_norm_stats: True # Freeze BN stats too
# ============================================================================

text_max_length: 350 # Max text length (not directly used by AmiVideoHFDataset, but good for reference)
accelerator: auto
# accelerator: gpu
weight_decay: 0.01
adam_epsilon: 1.0e-8
num_devices: 1

model_name: large-v2 # Whisper model size
learning_rate: 5.0e-6 # Reduced LR due to larger effective batch size

num_train_steps: 8000
warmup_steps: 1000

monitor: 'val/wer_av' # Monitor WER on the validation set for AV model (now only one val set)

video_model_ckpt: '/home/s2587130/AVSL/avsl/models/large_noise_pt_noise_ft_433h_only_weights.pt' # Path to AV-HuBERT weights
 

spec_augment: "ls-basic" # SpecAugment config for AmiVideoHFDataset ("ls-double", "ls-basic", or None)
dropout_rate: 0.1 # Dropout rate in Whisper model

lang: en # Language is English for AMI dataset
pt_ckpt: '/home/s2587130/AVSL/avsl/models/whisper_en_large.pt' # Path to pre-trained audio-only Whisper checkpoint (optional)
resume_training: False
train_id: whisper-flamingo_large_ft_ami_mem_opt # Updated train_id

video_projection_train_only: False
video_projection_separate_lr: '' # Not used
prob_use_av: 1.0 # For Whisper-Flamingo, no modality dropout in this config

# Video settings
use_av_hubert_encoder: True
add_gated_x_attn: 1 # 0 for False, 1 for True (enable Flamingo-style cross-attention)
av_fusion: separate # AV fusion strategy

log_output_dir: "/home/s2587130/AVSL/avsl/output/train_whisper_flamingo_ft" # Directory for TensorBoard logs
check_output_dir: "/home/s2587130/AVSL/avsl/checkpoints/whisper_flamingo_ft"   # Directory for model checkpoints

# Use local model directory instead of downloading
download_root: '/home/s2587130/AVSL/avsl/models/whisper' # Local directory where models are stored
